rm(list=ls())
# Load the npk data
data(npk)
# Load the necessary libraries
library(ggplot2)
library(ggfortify)
#Q1
#a
hist(npk$yield, breaks = "Sturges", probability = TRUE, main = "Histogram of Yield with Normal Curve",
xlab = "Yield of peas (lbs/plot)", col = "lightblue")
yield_mean <- mean(npk$yield)
yield_sd <- sd(npk$yield)
curve(dnorm(x, mean = yield_mean, sd = yield_sd), add = TRUE, col = "red", lwd = 2)
#b
shapiro_test <- shapiro.test(npk$yield)
print(shapiro_test)
#c
yield_mean <- mean(npk$yield)
yield_sd <- sd(npk$yield)
n <- length(npk$yield)
t_value <- qt(0.95, df = n - 1)
margin_error <- t_value * (yield_sd / sqrt(n))
ci_lower <- yield_mean + margin_error
cat("The 95% upper-tail confidence interval for the population mean of yield is:", yield_mean, "\n")
# Check
t_test_result <- t.test(npk$yield, alternative = "greater", conf.level = 0.95)
print(t_test_result)
#d
npk_with_nitrogen <- npk$yield[npk$N == 1]
wilcox_test <- wilcox.test(npk_with_nitrogen, mu = 55, alternative = "greater")
wilcox_test
#e
yields_with_nitrogen <- npk$yield[npk$N == 1]
yields_without_nitrogen <- npk$yield[npk$N == 0]
t_test_results <- t.test(yields_without_nitrogen, yields_with_nitrogen, alternative = "less", var.equal = FALSE)
t_test_results
boxplot(npk$yield ~ npk$N,
xlab = "Nitrogen used",
ylab = "Yield (lbs/plot)",
main = "Boxplot of Pea Yield with and without Nitrogen",
names = c("No Nitrogen", "Nitrogen"),
col = c("red", "green"))
# Q2
#a
boxplot(yield ~ interaction(block, N), data = npk,
xlab = "Block and Nitrogen Combination",
ylab = "Yield (lbs/plot)",
main = "Boxplot of Yield by Block and Nitrogen Combination",
col = c("blue", "green"),
las = 2)  # Rotate x-axis labels for better readability
#b
#c
anova_results <- aov(yield ~ block + N, data = npk)
anova_summary <- summary(anova_results)
print(anova_summary)
#d
tukey_results <- TukeyHSD(anova_results, which = "block")
print(tukey_results)
#e
autoplot(anova_results, which=1:6, ncol=3, label.size=3)
#for Q3 and 4
data(mtcars)
mtcars$vs <- factor(x=mtcars$vs, levels=c("0","1"))
#Q3
#a
# Fit the linear regression model
linear_model <- lm(qsec ~ mpg, data = mtcars)
# Extract the model coefficients
coefficients <- coef(linear_model)
# Write down the regression equation
cat("Regression equation: qsec = ", coefficients[1], " + ", coefficients[2], " * mpg", "\n")
# Predict the mpg for a qsec value of 17.5 seconds
predicted_mpg <- (17.5 - coefficients[1]) / coefficients[2]
# Output the predicted mpg
cat("Predicted vehicle fuel economy (mpg) for an average quarter mile time of 17.5s: ", predicted_mpg, "\n")
#b
summary_linear_model <- summary(linear_model)
mpg_coefficient_test <- summary_linear_model$coefficients["mpg", ]
mpg_coefficient_test
summary_linear_model
#c
# Install and load the necessary package for Durbin-Watson test
#install.packages("lmtest")
library(lmtest)
# Perform the Durbin-Watson test on the linear model
dw_test <- dwtest(linear_model)
# Output the results of the Durbin-Watson test
print(dw_test)
# Assuming you have the summary of the linear model stored in `summary_linear_model`
residual_standard_error <- summary_linear_model$sigma
# Estimate of σ^2
sigma_squared <- residual_standard_error^2
# Output the estimate of σ^2
sigma_squared
residual_standard_error <- summary_linear_model$sigma
sigma_squared <- residual_standard_error^2
sigma_squared
residual_standard_error <- summary_linear_model$sigma
sigma_squared <- residual_standard_error^2
sigma_squared
cooks_d <- cooks.distance(model)
rm(list=ls())
# Load the npk data
data(npk)
# Load the necessary libraries
library(ggplot2)
library(ggfortify)
#Q1
#a
hist(npk$yield, breaks = "Sturges", probability = TRUE, main = "Histogram of Yield with Normal Curve",
xlab = "Yield of peas (lbs/plot)", col = "lightblue")
yield_mean <- mean(npk$yield)
yield_sd <- sd(npk$yield)
curve(dnorm(x, mean = yield_mean, sd = yield_sd), add = TRUE, col = "red", lwd = 2)
#b
shapiro_test <- shapiro.test(npk$yield)
print(shapiro_test)
#c
yield_mean <- mean(npk$yield)
yield_sd <- sd(npk$yield)
n <- length(npk$yield)
t_value <- qt(0.95, df = n - 1)
margin_error <- t_value * (yield_sd / sqrt(n))
ci_lower <- yield_mean + margin_error
cat("The 95% upper-tail confidence interval for the population mean of yield is:", yield_mean, "\n")
# Check
t_test_result <- t.test(npk$yield, alternative = "greater", conf.level = 0.95)
print(t_test_result)
#d
npk_with_nitrogen <- npk$yield[npk$N == 1]
wilcox_test <- wilcox.test(npk_with_nitrogen, mu = 55, alternative = "greater")
wilcox_test
#e
yields_with_nitrogen <- npk$yield[npk$N == 1]
yields_without_nitrogen <- npk$yield[npk$N == 0]
t_test_results <- t.test(yields_without_nitrogen, yields_with_nitrogen, alternative = "less", var.equal = FALSE)
t_test_results
boxplot(npk$yield ~ npk$N,
xlab = "Nitrogen used",
ylab = "Yield (lbs/plot)",
main = "Boxplot of Pea Yield with and without Nitrogen",
names = c("No Nitrogen", "Nitrogen"),
col = c("red", "green"))
# Q2
#a
boxplot(yield ~ interaction(block, N), data = npk,
xlab = "Block and Nitrogen Combination",
ylab = "Yield (lbs/plot)",
main = "Boxplot of Yield by Block and Nitrogen Combination",
col = c("blue", "green"),
las = 2)  # Rotate x-axis labels for better readability
#b
#c
anova_results <- aov(yield ~ block + N, data = npk)
anova_summary <- summary(anova_results)
print(anova_summary)
#d
tukey_results <- TukeyHSD(anova_results, which = "block")
print(tukey_results)
#e
autoplot(anova_results, which=1:6, ncol=3, label.size=3)
#for Q3 and 4
data(mtcars)
mtcars$vs <- factor(x=mtcars$vs, levels=c("0","1"))
#Q3
#a
# Fit the linear regression model
linear_model <- lm(qsec ~ mpg, data = mtcars)
# Extract the model coefficients
coefficients <- coef(linear_model)
# Write down the regression equation
cat("Regression equation: qsec = ", coefficients[1], " + ", coefficients[2], " * mpg", "\n")
# Predict the mpg for a qsec value of 17.5 seconds
predicted_mpg <- (17.5 - coefficients[1]) / coefficients[2]
# Output the predicted mpg
cat("Predicted vehicle fuel economy (mpg) for an average quarter mile time of 17.5s: ", predicted_mpg, "\n")
#b
summary_linear_model <- summary(linear_model)
mpg_coefficient_test <- summary_linear_model$coefficients["mpg", ]
mpg_coefficient_test
summary_linear_model
#c
# Install and load the necessary package for Durbin-Watson test
#install.packages("lmtest")
library(lmtest)
# Perform the Durbin-Watson test on the linear model
dw_test <- dwtest(linear_model)
# Output the results of the Durbin-Watson test
print(dw_test)
#d
residual_standard_error <- summary_linear_model$sigma
sigma_squared <- residual_standard_error^2
sigma_squared
#q4
#a
# Create the scatter plot
ggplot(mtcars, aes(x = hp, y = qsec, color = factor(vs))) +
geom_point() +
scale_color_manual(values = c("1" = "blue", "0" = "red")) +
labs(color = "Engine Configuration", x = "Engine Horsepower (hp)", y = "Quarter Mile Time (qsec)") +
ggtitle("Scatter Plot of Quarter Mile Time vs. Engine Horsepower")
#b
# Ensure 'vs' is a factor if it's not already
mtcars$vs <- as.factor(mtcars$vs)
# Fit the model with interaction between 'hp' and 'vs'
model <- lm(qsec ~ mpg + hp + vs + hp:vs, data = mtcars)
# Output the summary of the model to get the coefficients
summary_model <- summary(model)
print(summary_model)
#d
# Assuming 'model' is your fitted regression model
# New data for prediction
new_data <- data.frame(mpg = 26.5, hp = 300, vs = factor(0, levels = c(0, 1)))
# Compute the prediction interval
prediction_interval <- predict(model, newdata = new_data, interval = "predict", level = 0.95)
# Output the prediction interval
print(prediction_interval)
#e
# Regress mpg on the other independent variables (hp, vs, and hp:vs)
model_mpg <- lm(mpg ~ hp + vs + hp:vs, data = mtcars)
# Get the summary of the model for mpg
summary_model_mpg <- summary(model_mpg)
# Calculate the R-squared value for the regression of mpg
r_squared_mpg <- summary_model_mpg$r.squared
# Calculate VIF for mpg
vif_mpg <- 1 / (1 - r_squared_mpg)
# Output the VIF for mpg
vif_mpg
cooks_d <- cooks.distance(model)
most_influential_point <- which.max(cooks_d)
max_cooks_d <- cooks_d[most_influential_point]
cat("The most influential point is observation number:", most_influential_point, "\n")
cat("The Cook's D of the most influential point is:", max_cooks_d, "\n")
cooks_distances <- cooks.distance(model)
n <- nrow(mtcars)
threshold <- 4 / n
influential_indices <- which(cooks_distances > threshold)
# Retrieve the Cook's D values for these influential points
influential_cooks_d <- cooks_distances[influential_indices]
# Print all influential points and their Cook's D values
cat("Indices of influential points based on Cook's D > ", threshold, ":\n")
print(influential_indices)
cat("\nCook's D values of these influential points:\n")
print(influential_cooks_d)
cooks_distances <- cooks.distance(model)
# Find the index of the maximum Cook's D value
most_influential_index <- which.max(cooks_distances)
# Retrieve the maximum Cook's D value
max_cooks_d <- cooks_distances[most_influential_index]
# Print the Cook's D value of the most influential point
cat("The Cook's D of the most influential point is:", max_cooks_d, "\n")
cat("The most influential point is at index:", most_influential_index, "\n")
# Exclude the most influential point from the dataset
mtcars_excluded <- mtcars[-most_influential_index, ]
# Refit the model without the most influential point
model_excluded <- lm(qsec ~ mpg + hp + vs + hp:vs, data = mtcars_excluded)
# Output the summary of the new model to get the coefficients
summary_model_excluded <- summary(model_excluded)
print(summary_model_excluded)
# Print the F-statistic and p-value directly from the summary
cat("F-Statistic: ", summary_original_model$fstatistic["value"], "\nP-value: ", summary_original_model$fstatistic["p.value"], "\n")
summary_original_model <- summary(model)
# Print the F-statistic and p-value directly from the summary
cat("F-Statistic: ", summary_original_model$fstatistic["value"], "\nP-value: ", summary_original_model$fstatistic["p.value"], "\n")
summary_original_model <- summary(model)
# Print the F-statistic and p-value directly from the summary
cat("F-Statistic: ", summary_original_model$fstatistic["value"], "\nP-value: ", summary_original_model$fstatistic["p.value"], "\n")
summary_original_model <- summary(model)
# Extract F-statistic and corresponding p-value
f_statistic_value <- summary_original_model$fstatistic["value"]
f_p_value <- summary(summary_original_model)$fstatistic[4] # Correctly access p-value
summary_original_model <- summary(model)
# Extract F-statistic and corresponding p-value
f_statistic_value <- summary_original_model$fstatistic["value"]
f_p_value <- summary(summary_original_model)$fstatistic[4] # Correctly access p-value
anova_table <- anova(model)
# Print the F-statistic and the p-value from the ANOVA table
cat("F-Statistic: ", anova_table["F value"], "\nP-value: ", anova_table["Pr(>F)"], "\n")
# Print the F-statistic and the p-value from the ANOVA table
anova_table
# Regress mpg on the other independent variables (hp, vs, and hp:vs)
model_mpg <- lm(mpg ~ hp + vs + hp:vs, data = mtcars)
# Get the summary of the model for mpg
summary_model_mpg <- summary(model_mpg)
# Calculate the R-squared value for the regression of mpg
r_squared_mpg <- summary_model_mpg$r.squared
# Calculate VIF for mpg
vif_mpg <- 1 / (1 - r_squared_mpg)
# Output the VIF for mpg
vif_mpg
model_mpg <- lm(mpg ~ hp + vs + hp:vs, data = mtcars)
summary_model_mpg <- summary(model_mpg)
r_squared_mpg <- summary_model_mpg$r.squared
vif <- 1 / (1 - r_squared_mpg)
vif
model_mpg <- lm(mpg ~ hp + vs + hp:vs, data = mtcars)
summary_model_mpg <- summary(model_mpg)
r_squared_mpg <- summary_model_mpg$r.squared
vif <- 1 / (1 - r_squared_mpg)
vif
anova_table <- anova(model)
# Print the F-statistic and the p-value from the ANOVA table
anova_table
overall_p_value <- model_anova['Pr(>F)'][nrow(model_anova)]
overall_p_value <- anova_table['Pr(>F)'][nrow(anova_table)]
View(npk)
f_statistic <- summary_model$fstatistic
f_value <- f_statistic["value"]
f_df1 <- f_statistic["numdf"]
f_df2 <- f_statistic["dendf"]
f_p_value <- pf(f_value, f_df1, f_df2, lower.tail = FALSE)
# Print the F-statistic and p-value
cat("F-Statistic: ", f_value, "\nP-value: ", f_p_value, "\n")
rm(list=ls())
# Load the npk data
data(npk)
# Load the necessary libraries
library(ggplot2)
library(ggfortify)
#Q1
#a
hist(npk$yield, breaks = "Sturges", probability = TRUE, main = "Histogram of Yield with Normal Curve",
xlab = "Yield of peas (lbs/plot)", col = "lightblue")
yield_mean <- mean(npk$yield)
yield_sd <- sd(npk$yield)
curve(dnorm(x, mean = yield_mean, sd = yield_sd), add = TRUE, col = "red", lwd = 2)
#b
shapiro_test <- shapiro.test(npk$yield)
print(shapiro_test)
#c
yield_mean <- mean(npk$yield)
yield_sd <- sd(npk$yield)
n <- length(npk$yield)
t_value <- qt(0.95, df = n - 1)
margin_error <- t_value * (yield_sd / sqrt(n))
ci_upper <- yield_mean + margin_error  # Cambiado a ci_upper para reflejar que es el límite superior
cat("The 95% upper-tail confidence interval for the population mean of yield is above", yield_mean, "up to", ci_upper, "\n")
# Check
t_test_result <- t.test(npk$yield, alternative = "greater", conf.level = 0.95)
print(t_test_result)
npk_with_nitrogen <- npk$yield[npk$N == 1]
wilcox_test <- wilcox.test(npk_with_nitrogen, mu = 55, alternative = "greater")
wilcox_test
yields_with_nitrogen <- npk$yield[npk$N == 1]
yields_without_nitrogen <- npk$yield[npk$N == 0]
t_test_results <- t.test(yields_without_nitrogen, yields_with_nitrogen, alternative = "less", var.equal = FALSE)
t_test_results
boxplot(npk$yield ~ npk$N,
xlab = "Nitrogen used",
ylab = "Yield (lbs/plot)",
main = "Boxplot of Pea Yield with and without Nitrogen",
names = c("No Nitrogen", "Nitrogen"),
col = c("red", "green"))
# Q2
#a
boxplot(yield ~ interaction(block, N), data = npk,
xlab = "Block and Nitrogen Combination",
ylab = "Yield (lbs/plot)",
main = "Boxplot of Yield by Block and Nitrogen Combination",
col = c("blue", "green"),
las = 2)  # Rotate x-axis labels for better readability
anova_results <- aov(yield ~ block + N, data = npk)
anova_summary <- summary(anova_results)
print(anova_summary)
tukey_results <- TukeyHSD(anova_results, which = "block")
print(tukey_results)
autoplot(anova_results, which=1:6, ncol=3, label.size=3)
#for Q3 and 4
data(mtcars)
mtcars$vs <- factor(x=mtcars$vs, levels=c("0","1"))
#a
# Fit the linear regression model
linear_model <- lm(qsec ~ mpg, data = mtcars)
# Extract the model coefficients
coefficients <- coef(linear_model)
# Write down the regression equation
cat("Regression equation: qsec = ", coefficients[1], " + ", coefficients[2], " * mpg", "\n")
# Predict the mpg for a qsec value of 17.5 seconds
predicted_mpg <- (17.5 - coefficients[1]) / coefficients[2]
# Output the predicted mpg
cat("Predicted vehicle fuel economy (mpg) for an average quarter mile time of 17.5s: ", predicted_mpg, "\n")
cat("Predicted vehicle fuel economy (mpg) for an average quarter mile time of 17.5s: ", predicted_mpg, "\n")
summary_linear_model <- summary(linear_model)
mpg_coefficient_test <- summary_linear_model$coefficients["mpg", ]
mpg_coefficient_test
summary_linear_model
# Install and load the necessary package for Durbin-Watson test
#install.packages("lmtest")
library(lmtest)
# Output the results of the Durbin-Watson test
print(dw_test)
residual_standard_error <- summary_linear_model$sigma
sigma_squared <- residual_standard_error^2
sigma_squared
residual_standard_error <- summary_linear_model$sigma
sigma_squared <- residual_standard_error^2
cat("Estimated variance of errors (sigma^2) is:", sigma_squared, "\n")
# Create the scatter plot
ggplot(mtcars, aes(x = hp, y = qsec, color = factor(vs))) +
geom_point() +
scale_color_manual(values = c("1" = "blue", "0" = "red")) +
labs(color = "Engine Configuration", x = "Engine Horsepower (hp)", y = "Quarter Mile Time (qsec)") +
ggtitle("Scatter Plot of Quarter Mile Time vs. Engine Horsepower")
# Ensure 'vs' is a factor if it's not already
mtcars$vs <- as.factor(mtcars$vs)
# Fit the model with interaction between 'hp' and 'vs'
model <- lm(qsec ~ mpg + hp + vs + hp:vs, data = mtcars)
# Output the summary of the model to get the coefficients
summary_model <- summary(model)
print(summary_model)
#C
anova_table <- anova(model)
f_statistic <- summary_model$fstatistic
f_value <- f_statistic["value"]
f_df1 <- f_statistic["numdf"]
f_df2 <- f_statistic["dendf"]
f_p_value <- pf(f_value, f_df1, f_df2, lower.tail = FALSE)
# Print the F-statistic and p-value
cat("F-Statistic: ", f_value, "\nP-value: ", f_p_value, "\n")
# Print the F-statistic and the p-value from the ANOVA table
anova_table
# New data for prediction
new_data <- data.frame(mpg = 26.5, hp = 300, vs = factor(0, levels = c(0, 1)))
# Compute the prediction interval
prediction_interval <- predict(model, newdata = new_data, interval = "predict", level = 0.95)
# Output the prediction interval
print(prediction_interval)
model_mpg <- lm(mpg ~ hp + vs + hp:vs, data = mtcars)
summary_model_mpg <- summary(model_mpg)
r_squared_mpg <- summary_model_mpg$r.squared
vif <- 1 / (1 - r_squared_mpg)
vif
model_for_vif <- lm(mpg ~ hp + vs + hp:vs, data=mtcars)
summary_model_for_vif <- summary(model_for_vif)
r_squared_for_vif <- summary_model_for_vif$r.squared
vif_mpg <- 1 / (1 - r_squared_for_vif)
cat("VIF for mpg is:", vif_mpg, "\n")
